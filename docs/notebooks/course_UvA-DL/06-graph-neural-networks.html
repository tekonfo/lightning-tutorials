


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-PQBQ3CV');
  </script>
  <!-- End Google Tag Manager -->

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="google-site-verification" content="okUst94cAlWSsUsGZTB4xSS4UKTtRV8Nu5XZ9pdd3Aw" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tutorial 6: Basics of Graph Neural Networks &mdash; lightning-tutorials  documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/icon.svg"/>
  
  
  
    <link rel="canonical" href="https://www.pytorchlightning.ai/notebooks/course_UvA-DL/06-graph-neural-networks.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sphinx_paramlinks.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Tutorial 7: Deep Energy-Based Generative Models" href="07-deep-energy-based-generative-models.html" />
    <link rel="prev" title="Tutorial 5: Transformers and Multi-Head Attention" href="05-transformers-and-MH-attention.html" />
  <!-- Google Analytics -->
  
  <!-- End Google Analytics -->
  

  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pt-lightning-sandbox.rtfd.io/en/latest/" aria-label="PyTorch">
      <!--  <img class="call-to-action-img" src="../../_static/images/logo-lightning-icon.png"/> -->
      </a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pt-lightning-sandbox.readthedocs.io/en/latest/introduction_guide.html">Get Started</a>
          </li>

          <li>
            <a href="https://www.pytorchlightning.ai/blog">Blog</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch-lightning.readthedocs.io/en/stable/">
                  <span class="dropdown-title">PyTorch Lightning</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://torchmetrics.readthedocs.io/en/stable/">
                  <span class="dropdown-title">TorchMetrics</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-flash.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Flash</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-transformers.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Transformers</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-bolts.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Bolts</span>
                  <p></p>
                </a>
            </div>
          </li>

          <!--<li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pt-lightning-sandbox.readthedocs.io/en/latest/#community-examples">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>-->

          <li>
            <a href="https://github.com/PytorchLightning/lightning-sandbox">GitHub</a>
          </li>

          <li>
            <a href="https://www.grid.ai/">Grid.ai</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Start here</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../sample-template.html">How to write a PyTorch Lightning tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-introduction-to-pytorch.html">Tutorial 1: Introduction to PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="02-activation-functions.html">Tutorial 2: Activation Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-initialization-and-optimization.html">Tutorial 3: Initialization and Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-inception-resnet-densenet.html">Tutorial 4: Inception, ResNet and DenseNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="05-transformers-and-MH-attention.html">Tutorial 5: Transformers and Multi-Head Attention</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tutorial 6: Basics of Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-deep-energy-based-generative-models.html">Tutorial 7: Deep Energy-Based Generative Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-deep-autoencoders.html">Tutorial 8: Deep Autoencoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="09-normalizing-flows.html">Tutorial 9: Normalizing Flows for Image Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="10-autoregressive-image-modeling.html">Tutorial 10: Autoregressive Image Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-vision-transformer.html">Tutorial 11: Vision Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="12-meta-learning.html">Tutorial 12: Meta-Learning - Learning to Learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="13-contrastive-learning.html">Tutorial 13: Self-Supervised Contrastive Learning with SimCLR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lightning_examples/augmentation_kornia.html">GPU and batched data augmentation with Kornia and PyTorch-Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lightning_examples/barlow-twins.html">Barlow Twins Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lightning_examples/basic-gan.html">PyTorch Lightning Basic GAN Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lightning_examples/cifar10-baseline.html">PyTorch Lightning CIFAR10 ~94% Baseline Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lightning_examples/datamodules.html">PyTorch Lightning DataModules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lightning_examples/mnist-hello-world.html">Introduction to Pytorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lightning_examples/mnist-tpu-training.html">TPU training with PyTorch Lightning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lightning_examples/reinforce-learning-DQN.html">How to train a Deep Q Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lightning_examples/text-transformers.html">Finetune Transformers Models with PyTorch Lightning</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Tutorial 6: Basics of Graph Neural Networks</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../_sources/notebooks/course_UvA-DL/06-graph-neural-networks.ipynb.txt" rel="nofollow"><img src="../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="Tutorial-6:-Basics-of-Graph-Neural-Networks">
<h1>Tutorial 6: Basics of Graph Neural Networks<a class="headerlink" href="#Tutorial-6:-Basics-of-Graph-Neural-Networks" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><strong>Author:</strong> Phillip Lippe</p></li>
<li><p><strong>License:</strong> CC BY-SA</p></li>
<li><p><strong>Generated:</strong> 2021-09-16T14:32:27.913918</p></li>
</ul>
<p>In this tutorial, we will discuss the application of neural networks on graphs. Graph Neural Networks (GNNs) have recently gained increasing popularity in both applications and research, including domains such as social networks, knowledge graphs, recommender systems, and bioinformatics. While the theory and math behind GNNs might first seem complicated, the implementation of those models is quite simple and helps in understanding the methodology. Therefore, we will discuss the implementation of
basic network layers of a GNN, namely graph convolutions, and attention layers. Finally, we will apply a GNN on semi-supervised node classification and molecule categorization. This notebook is part of a lecture series on Deep Learning at the University of Amsterdam. The full list of tutorials can be found at <a class="reference external" href="https://uvadlc-notebooks.rtfd.io">https://uvadlc-notebooks.rtfd.io</a>.</p>
<hr class="docutils" />
<p>Open in <a class="reference external" href="https://colab.research.google.com/github/PytorchLightning/lightning-tutorials/blob/publication/.notebooks/course_UvA-DL/06-graph-neural-networks.ipynb"><img alt="Open In Colab" src="data:image/png;base64,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" style="width: 117px; height: 20px;" /></a></p>
<p>Give us a ⭐ <a class="reference external" href="https://www.github.com/PytorchLightning/pytorch-lightning/">on Github</a> | Check out <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/latest/">the documentation</a> | Join us <a class="reference external" href="https://join.slack.com/t/pytorch-lightning/shared_invite/zt-pw5v393p-qRaDgEk24~EjiZNBpSQFgQ">on Slack</a></p>
<section id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Permalink to this headline">¶</a></h2>
<p>This notebook requires some packages besides pytorch-lightning.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># ! pip install --quiet &quot;torch-scatter&quot; &quot;pytorch-lightning&gt;=1.3&quot; &quot;torchmetrics&gt;=0.3&quot; &quot;torch&gt;=1.6, &lt;1.9&quot; &quot;torch-spline-conv&quot; &quot;torch-cluster&quot; &quot;torch-sparse&quot; &quot;torch-geometric==1.7.2&quot;</span>
</pre></div>
</div>
</div>
<div class="center-wrapper"><div class="video-wrapper"><iframe src="https://www.youtube.com/embed/fK7d56Ly9q8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div></div><p>We start by importing our standard libraries below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Standard libraries</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># For downloading pre-trained models</span>
<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">from</span> <span class="nn">urllib.error</span> <span class="kn">import</span> <span class="n">HTTPError</span>

<span class="c1"># PyTorch Lightning</span>
<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>

<span class="c1"># PyTorch</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="c1"># PyTorch geometric</span>
<span class="kn">import</span> <span class="nn">torch_geometric</span>
<span class="kn">import</span> <span class="nn">torch_geometric.data</span> <span class="k">as</span> <span class="nn">geom_data</span>
<span class="kn">import</span> <span class="nn">torch_geometric.nn</span> <span class="k">as</span> <span class="nn">geom_nn</span>

<span class="c1"># PL callbacks</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>

<span class="n">AVAIL_GPUS</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">())</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span> <span class="k">if</span> <span class="n">AVAIL_GPUS</span> <span class="k">else</span> <span class="mi">64</span>
<span class="c1"># Path to the folder where the datasets are/should be downloaded</span>
<span class="n">DATASET_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;PATH_DATASETS&quot;</span><span class="p">,</span> <span class="s2">&quot;data/&quot;</span><span class="p">)</span>
<span class="c1"># Path to the folder where the pretrained models are saved</span>
<span class="n">CHECKPOINT_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;PATH_CHECKPOINT&quot;</span><span class="p">,</span> <span class="s2">&quot;saved_models/GNNs/&quot;</span><span class="p">)</span>

<span class="c1"># Setting the seed</span>
<span class="n">pl</span><span class="o">.</span><span class="n">seed_everything</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Ensure that all operations are deterministic on GPU (if used) for reproducibility</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">determinstic</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Global seed set to 42
</pre></div></div>
</div>
<p>We also have a few pre-trained models we download below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Github URL where saved models are stored for this tutorial</span>
<span class="n">base_url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/&quot;</span>
<span class="c1"># Files to download</span>
<span class="n">pretrained_files</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;NodeLevelMLP.ckpt&quot;</span><span class="p">,</span> <span class="s2">&quot;NodeLevelGNN.ckpt&quot;</span><span class="p">,</span> <span class="s2">&quot;GraphLevelGraphConv.ckpt&quot;</span><span class="p">]</span>

<span class="c1"># Create checkpoint path if it doesn&#39;t exist yet</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># For each file, check whether it already exists. If not, try downloading it.</span>
<span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">pretrained_files</span><span class="p">:</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;/&quot;</span> <span class="ow">in</span> <span class="n">file_name</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">file_path</span><span class="o">.</span><span class="n">rsplit</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
        <span class="n">file_url</span> <span class="o">=</span> <span class="n">base_url</span> <span class="o">+</span> <span class="n">file_name</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloading </span><span class="si">%s</span><span class="s2">...&quot;</span> <span class="o">%</span> <span class="n">file_url</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">file_url</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">HTTPError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">&quot;Something went wrong. Please try to download the file from the GDrive folder,&quot;</span>
                <span class="s2">&quot; or contact the author with the full output including the following error:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">e</span><span class="p">,</span>
            <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelMLP.ckpt...
Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelGNN.ckpt...
Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/GraphLevelGraphConv.ckpt...
</pre></div></div>
</div>
</section>
<section id="Graph-Neural-Networks">
<h2>Graph Neural Networks<a class="headerlink" href="#Graph-Neural-Networks" title="Permalink to this headline">¶</a></h2>
<section id="Graph-representation">
<h3>Graph representation<a class="headerlink" href="#Graph-representation" title="Permalink to this headline">¶</a></h3>
<p>Before starting the discussion of specific neural network operations on graphs, we should consider how to represent a graph. Mathematically, a graph <img class="math" src="../../_images/math/6dcb07d85c521a57d23e5281206d5de945f43b92.png" alt="\mathcal{G}"/> is defined as a tuple of a set of nodes/vertices <img class="math" src="../../_images/math/e4762cec46619bf7781cae62216214f909395368.png" alt="V"/>, and a set of edges/links <img class="math" src="../../_images/math/1815f600df7845409443aed470eac2d449e4ddb0.png" alt="E"/>: <img class="math" src="../../_images/math/5d41b97b8d0b0c455941a7735dea81839d81a8b1.png" alt="\mathcal{G}=(V,E)"/>. Each edge is a pair of two vertices, and represents a connection between them. For instance, let’s look at the following graph:</p>
<center width="100%" style="padding:10px"><p><img alt="ddbf9f5dba9f4b58bb1b84eb7889bfb5" class="no-scaled-link" src="https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/06-graph-neural-networks/example_graph.svg" width="250px" /></p>
</center><p>The vertices are <img class="math" src="../../_images/math/01c09ea71f15566e14a3c8e332754f91d876b5d0.png" alt="V=\{1,2,3,4\}"/>, and edges <img class="math" src="../../_images/math/3592eb13a11159c1590fee39a85bad399f104e58.png" alt="E=\{(1,2), (2,3), (2,4), (3,4)\}"/>. Note that for simplicity, we assume the graph to be undirected and hence don’t add mirrored pairs like <img class="math" src="../../_images/math/175d1f19f92137a77472ca70f3587ae2ebd59ce0.png" alt="(2,1)"/>. In application, vertices and edge can often have specific attributes, and edges can even be directed. The question is how we could represent this diversity in an efficient way for matrix operations. Usually, for the edges, we decide between two variants: an adjacency matrix, or a list of
paired vertex indices.</p>
<p>The <strong>adjacency matrix</strong> <img class="math" src="../../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/> is a square matrix whose elements indicate whether pairs of vertices are adjacent, i.e. connected, or not. In the simplest case, <img class="math" src="../../_images/math/f0ae456df40291bb45cbd97cb622153b7a01d6b6.png" alt="A_{ij}"/> is 1 if there is a connection from node <img class="math" src="../../_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.png" alt="i"/> to <img class="math" src="../../_images/math/e3fc28292267f066fee7718c64f4bbfece521f24.png" alt="j"/>, and otherwise 0. If we have edge attributes or different categories of edges in a graph, this information can be added to the matrix as well. For an undirected graph, keep in mind that <img class="math" src="../../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/> is a symmetric matrix (<img class="math" src="../../_images/math/23b4ec9ee2ab8ee6e457a32639a35cc6773c4664.png" alt="A_{ij}=A_{ji}"/>). For the example
graph above, we have the following adjacency matrix:</p>
<div class="math">
<p><img src="../../_images/math/1254d2883914e52605b9744e67a5e4b3e269aa48.png" alt="A = \begin{bmatrix}
    0 &amp; 1 &amp; 0 &amp; 0\\
    1 &amp; 0 &amp; 1 &amp; 1\\
    0 &amp; 1 &amp; 0 &amp; 1\\
    0 &amp; 1 &amp; 1 &amp; 0
\end{bmatrix}"/></p>
</div><p>While expressing a graph as a list of edges is more efficient in terms of memory and (possibly) computation, using an adjacency matrix is more intuitive and simpler to implement. In our implementations below, we will rely on the adjacency matrix to keep the code simple. However, common libraries use edge lists, which we will discuss later more. Alternatively, we could also use the list of edges to define a sparse adjacency matrix with which we can work as if it was a dense matrix, but allows
more memory-efficient operations. PyTorch supports this with the sub-package <code class="docutils literal notranslate"><span class="pre">torch.sparse</span></code> (<a class="reference external" href="https://pytorch.org/docs/stable/sparse.html">documentation</a>) which is however still in a beta-stage (API might change in future).</p>
</section>
<section id="Graph-Convolutions">
<h3>Graph Convolutions<a class="headerlink" href="#Graph-Convolutions" title="Permalink to this headline">¶</a></h3>
<p>Graph Convolutional Networks have been introduced by <a class="reference external" href="https://openreview.net/pdf?id=SJU4ayYgl">Kipf et al. </a> in 2016 at the University of Amsterdam. He also wrote a great <a class="reference external" href="https://tkipf.github.io/graph-convolutional-networks/">blog post</a> about this topic, which is recommended if you want to read about GCNs from a different perspective. GCNs are similar to convolutions in images in the sense that the “filter” parameters are typically shared over all locations in the graph. At the same time,
GCNs rely on message passing methods, which means that vertices exchange information with the neighbors, and send “messages” to each other. Before looking at the math, we can try to visually understand how GCNs work. The first step is that each node creates a feature vector that represents the message it wants to send to all its neighbors. In the second step, the messages are sent to the neighbors, so that a node receives one message per adjacent node. Below we have visualized the two steps for
our example graph.</p>
<center width="100%" style="padding:10px"><p><img alt="880937d8da664c09aa6552e01c6662d8" class="no-scaled-link" src="https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/06-graph-neural-networks/graph_message_passing.svg" width="700px" /></p>
</center><p>If we want to formulate that in more mathematical terms, we need to first decide how to combine all the messages a node receives. As the number of messages vary across nodes, we need an operation that works for any number. Hence, the usual way to go is to sum or take the mean. Given the previous features of nodes <img class="math" src="../../_images/math/ee8025a3b7259dbe7b156c5e4d96a9d7c0411996.png" alt="H^{(l)}"/>, the GCN layer is defined as follows:</p>
<div class="math">
<p><img src="../../_images/math/b21e82b2800d65305dbe38f312c8e5583124ae40.png" alt="H^{(l+1)} = \sigma\left(\hat{D}^{-1/2}\hat{A}\hat{D}^{-1/2}H^{(l)}W^{(l)}\right)"/></p>
</div><p><img class="math" src="../../_images/math/77b9caa6d45c4df856d3eb8206c10c5d2b22b35c.png" alt="W^{(l)}"/> is the weight parameters with which we transform the input features into messages (<img class="math" src="../../_images/math/d904044380ab56227dad8239639f958102d4d581.png" alt="H^{(l)}W^{(l)}"/>). To the adjacency matrix <img class="math" src="../../_images/math/211284f68205c3e66773eaf026f32a0acdd3dfb3.png" alt="A"/> we add the identity matrix so that each node sends its own message also to itself: <img class="math" src="../../_images/math/1932a3033b48860efa6e33807823321ad781d9d0.png" alt="\hat{A}=A+I"/>. Finally, to take the average instead of summing, we calculate the matrix <img class="math" src="../../_images/math/22c4e6d801b3403a51bb167d8a2067669f796935.png" alt="\hat{D}"/> which is a diagonal matrix with <img class="math" src="../../_images/math/1ab1e1ab629f8acd123d763a4f19fdbf8a9504bf.png" alt="D_{ii}"/> denoting the number of neighbors node <img class="math" src="../../_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.png" alt="i"/> has. <img class="math" src="../../_images/math/b52df27bfb0b1e3af0c2c68a7b9da459178c2a7d.png" alt="\sigma"/> represents an arbitrary activation
function, and not necessarily the sigmoid (usually a ReLU-based activation function is used in GNNs).</p>
<p>When implementing the GCN layer in PyTorch, we can take advantage of the flexible operations on tensors. Instead of defining a matrix <img class="math" src="../../_images/math/22c4e6d801b3403a51bb167d8a2067669f796935.png" alt="\hat{D}"/>, we can simply divide the summed messages by the number of neighbors afterward. Additionally, we replace the weight matrix with a linear layer, which additionally allows us to add a bias. Written as a PyTorch module, the GCN layer is defined as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">GCNLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_in</span><span class="p">,</span> <span class="n">c_out</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">c_in</span><span class="p">,</span> <span class="n">c_out</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_feats</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            node_feats: Tensor with node features of shape [batch_size, num_nodes, c_in]</span>
<span class="sd">            adj_matrix: Batch of adjacency matrices of the graph. If there is an edge from i to j,</span>
<span class="sd">                         adj_matrix[b,i,j]=1 else 0. Supports directed edges by non-symmetric matrices.</span>
<span class="sd">                         Assumes to already have added the identity connections.</span>
<span class="sd">                         Shape: [batch_size, num_nodes, num_nodes]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Num neighbours = number of incoming edges</span>
        <span class="n">num_neighbours</span> <span class="o">=</span> <span class="n">adj_matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">node_feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">node_feats</span><span class="p">)</span>
        <span class="n">node_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">adj_matrix</span><span class="p">,</span> <span class="n">node_feats</span><span class="p">)</span>
        <span class="n">node_feats</span> <span class="o">=</span> <span class="n">node_feats</span> <span class="o">/</span> <span class="n">num_neighbours</span>
        <span class="k">return</span> <span class="n">node_feats</span>
</pre></div>
</div>
</div>
<p>To further understand the GCN layer, we can apply it to our example graph above. First, let’s specify some node features and the adjacency matrix with added self-connections:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">node_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">adj_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Node features:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">node_feats</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Adjacency matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Node features:
 tensor([[[0., 1.],
         [2., 3.],
         [4., 5.],
         [6., 7.]]])

Adjacency matrix:
 tensor([[[1., 1., 0., 0.],
         [1., 1., 1., 1.],
         [0., 1., 1., 1.],
         [0., 1., 1., 1.]]])
</pre></div></div>
</div>
<p>Next, let’s apply a GCN layer to it. For simplicity, we initialize the linear weight matrix as an identity matrix so that the input features are equal to the messages. This makes it easier for us to verify the message passing operation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">layer</span> <span class="o">=</span> <span class="n">GCNLayer</span><span class="p">(</span><span class="n">c_in</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">c_out</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">layer</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span>
<span class="n">layer</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">out_feats</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">node_feats</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Adjacency matrix&quot;</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input features&quot;</span><span class="p">,</span> <span class="n">node_feats</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output features&quot;</span><span class="p">,</span> <span class="n">out_feats</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Adjacency matrix tensor([[[1., 1., 0., 0.],
         [1., 1., 1., 1.],
         [0., 1., 1., 1.],
         [0., 1., 1., 1.]]])
Input features tensor([[[0., 1.],
         [2., 3.],
         [4., 5.],
         [6., 7.]]])
Output features tensor([[[1., 2.],
         [3., 4.],
         [4., 5.],
         [4., 5.]]])
</pre></div></div>
</div>
<p>As we can see, the first node’s output values are the average of itself and the second node. Similarly, we can verify all other nodes. However, in a GNN, we would also want to allow feature exchange between nodes beyond its neighbors. This can be achieved by applying multiple GCN layers, which gives us the final layout of a GNN. The GNN can be build up by a sequence of GCN layers and non-linearities such as ReLU. For a visualization, see below (figure credit - <a class="reference external" href="https://tkipf.github.io/graph-convolutional-networks/">Thomas Kipf,
2016</a>).</p>
<center width="100%" style="padding: 10px"><p><img alt="73d89d51fa5249a69efb24a2daafc00e" class="no-scaled-link" src="https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/06-graph-neural-networks/gcn_network.png" style="width: 600px;" /></p>
</center><p>However, one issue we can see from looking at the example above is that the output features for nodes 3 and 4 are the same because they have the same adjacent nodes (including itself). Therefore, GCN layers can make the network forget node-specific information if we just take a mean over all messages. Multiple possible improvements have been proposed. While the simplest option might be using residual connections, the more common approach is to either weigh the self-connections higher or define a
separate weight matrix for the self-connections. Alternatively, we can use a well-known concept: attention.</p>
</section>
<section id="Graph-Attention">
<h3>Graph Attention<a class="headerlink" href="#Graph-Attention" title="Permalink to this headline">¶</a></h3>
<p>Attention describes a weighted average of multiple elements with the weights dynamically computed based on an input query and elements’ keys (if you don’t know what attention is, it is recommended to at least go through the very first section called <a class="reference external" href="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html#What-is-Attention?">What is Attention?</a>). This concept can be similarly applied to graphs, one of such is the Graph Attention Network
(called GAT, proposed by <a class="reference external" href="https://arxiv.org/abs/1710.10903">Velickovic et al., 2017</a>). Similarly to the GCN, the graph attention layer creates a message for each node using a linear layer/weight matrix. For the attention part, it uses the message from the node itself as a query, and the messages to average as both keys and values (note that this also includes the message to itself). The score function <img class="math" src="../../_images/math/064e566624869cbe4f4d0995090751a3fc47e7f5.png" alt="f_{attn}"/> is implemented as a one-layer MLP which maps the query and key to a single
value. The MLP looks as follows (figure credit - <a class="reference external" href="https://arxiv.org/abs/1710.10903">Velickovic et al. </a>):</p>
<center width="100%" style="padding:10px"><p><img alt="2d870055434a44f5a4dfd4aac29d382c" class="no-scaled-link" src="https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/06-graph-neural-networks/graph_attention_MLP.svg" width="250px" /></p>
</center><p><img class="math" src="../../_images/math/b6e2c1bc7d8a8ef8bc3878348c32e442f102d286.png" alt="h_i"/> and <img class="math" src="../../_images/math/62392d64151f07fa5f984d2f5898716cf5637d9e.png" alt="h_j"/> are the original features from node <img class="math" src="../../_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.png" alt="i"/> and <img class="math" src="../../_images/math/e3fc28292267f066fee7718c64f4bbfece521f24.png" alt="j"/> respectively, and represent the messages of the layer with <img class="math" src="../../_images/math/a2e331d4d03aaed9125c103edf6a40e16b95daaf.png" alt="\mathbf{W}"/> as weight matrix. <img class="math" src="../../_images/math/ee06d542263974017a04fb2dc754e9708a8f749f.png" alt="\mathbf{a}"/> is the weight matrix of the MLP, which has the shape <img class="math" src="../../_images/math/f735e4341797b074ccad0474b63652160e930a9f.png" alt="[1,2\times d_{\text{message}}]"/>, and <img class="math" src="../../_images/math/5608fb612bb0204317f50a43e89cc503415a5012.png" alt="\alpha_{ij}"/> the final attention weight from node <img class="math" src="../../_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.png" alt="i"/> to <img class="math" src="../../_images/math/e3fc28292267f066fee7718c64f4bbfece521f24.png" alt="j"/>. The calculation can be described as follows:</p>
<div class="math">
<p><img src="../../_images/math/98aadee344ee6e56ab856087cd20271749f74324.png" alt="\alpha_{ij} = \frac{\exp\left(\text{LeakyReLU}\left(\mathbf{a}\left[\mathbf{W}h_i||\mathbf{W}h_j\right]\right)\right)}{\sum_{k\in\mathcal{N}_i} \exp\left(\text{LeakyReLU}\left(\mathbf{a}\left[\mathbf{W}h_i||\mathbf{W}h_k\right]\right)\right)}"/></p>
</div><p>The operator <img class="math" src="../../_images/math/13565b2a76c21855cc88414af72b28924cf42490.png" alt="||"/> represents the concatenation, and <img class="math" src="../../_images/math/fc542678b02bf527afbed838a5fc74c67690e4d8.png" alt="\mathcal{N}_i"/> the indices of the neighbors of node <img class="math" src="../../_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.png" alt="i"/>. Note that in contrast to usual practice, we apply a non-linearity (here LeakyReLU) before the softmax over elements. Although it seems like a minor change at first, it is crucial for the attention to depend on the original input. Specifically, let’s remove the non-linearity for a second, and try to simplify the expression:</p>
<div class="math">
<p><img src="../../_images/math/7af59355e713f04c71feddd458a77565f858d03d.png" alt="\begin{split}
    \alpha_{ij} &amp; = \frac{\exp\left(\mathbf{a}\left[\mathbf{W}h_i||\mathbf{W}h_j\right]\right)}{\sum_{k\in\mathcal{N}_i} \exp\left(\mathbf{a}\left[\mathbf{W}h_i||\mathbf{W}h_k\right]\right)}\\[5pt]
    &amp; = \frac{\exp\left(\mathbf{a}_{:,:d/2}\mathbf{W}h_i+\mathbf{a}_{:,d/2:}\mathbf{W}h_j\right)}{\sum_{k\in\mathcal{N}_i} \exp\left(\mathbf{a}_{:,:d/2}\mathbf{W}h_i+\mathbf{a}_{:,d/2:}\mathbf{W}h_k\right)}\\[5pt]
    &amp; = \frac{\exp\left(\mathbf{a}_{:,:d/2}\mathbf{W}h_i\right)\cdot\exp\left(\mathbf{a}_{:,d/2:}\mathbf{W}h_j\right)}{\sum_{k\in\mathcal{N}_i} \exp\left(\mathbf{a}_{:,:d/2}\mathbf{W}h_i\right)\cdot\exp\left(\mathbf{a}_{:,d/2:}\mathbf{W}h_k\right)}\\[5pt]
    &amp; = \frac{\exp\left(\mathbf{a}_{:,d/2:}\mathbf{W}h_j\right)}{\sum_{k\in\mathcal{N}_i} \exp\left(\mathbf{a}_{:,d/2:}\mathbf{W}h_k\right)}\\
\end{split}"/></p>
</div><p>We can see that without the non-linearity, the attention term with <img class="math" src="../../_images/math/b6e2c1bc7d8a8ef8bc3878348c32e442f102d286.png" alt="h_i"/> actually cancels itself out, resulting in the attention being independent of the node itself. Hence, we would have the same issue as the GCN of creating the same output features for nodes with the same neighbors. This is why the LeakyReLU is crucial and adds some dependency on <img class="math" src="../../_images/math/b6e2c1bc7d8a8ef8bc3878348c32e442f102d286.png" alt="h_i"/> to the attention.</p>
<p>Once we obtain all attention factors, we can calculate the output features for each node by performing the weighted average:</p>
<div class="math">
<p><img src="../../_images/math/d0831adb691182f44ca3617db33049726f128ce1.png" alt="h_i'=\sigma\left(\sum_{j\in\mathcal{N}_i}\alpha_{ij}\mathbf{W}h_j\right)"/></p>
</div><p><img class="math" src="../../_images/math/b52df27bfb0b1e3af0c2c68a7b9da459178c2a7d.png" alt="\sigma"/> is yet another non-linearity, as in the GCN layer. Visually, we can represent the full message passing in an attention layer as follows (figure credit - <a class="reference external" href="https://arxiv.org/abs/1710.10903">Velickovic et al. </a>):</p>
<center width="100%"><p><img alt="8bd4baa3b4244dd99a56ae1ef9d289c9" class="no-scaled-link" src="https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/06-graph-neural-networks/graph_attention.jpeg" style="width: 400px;" /></p>
</center><p>To increase the expressiveness of the graph attention network, <a class="reference external" href="https://arxiv.org/abs/1710.10903">Velickovic et al. </a> proposed to extend it to multiple heads similar to the Multi-Head Attention block in Transformers. This results in <img class="math" src="../../_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.png" alt="N"/> attention layers being applied in parallel. In the image above, it is visualized as three different colors of arrows (green, blue, and purple) that are afterward concatenated. The average is only applied for the very final prediction layer in a network.</p>
<p>After having discussed the graph attention layer in detail, we can implement it below:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">GATLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_in</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">concat_heads</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            c_in: Dimensionality of input features</span>
<span class="sd">            c_out: Dimensionality of output features</span>
<span class="sd">            num_heads: Number of heads, i.e. attention mechanisms to apply in parallel. The</span>
<span class="sd">                        output features are equally split up over the heads if concat_heads=True.</span>
<span class="sd">            concat_heads: If True, the output of the different heads is concatenated instead of averaged.</span>
<span class="sd">            alpha: Negative slope of the LeakyReLU activation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat_heads</span> <span class="o">=</span> <span class="n">concat_heads</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_heads</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">c_out</span> <span class="o">%</span> <span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Number of output features must be a multiple of the count of heads.&quot;</span>
            <span class="n">c_out</span> <span class="o">=</span> <span class="n">c_out</span> <span class="o">//</span> <span class="n">num_heads</span>

        <span class="c1"># Sub-modules and parameters needed in the layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">c_in</span><span class="p">,</span> <span class="n">c_out</span> <span class="o">*</span> <span class="n">num_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">num_heads</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">c_out</span><span class="p">))</span>  <span class="c1"># One per head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leakyrelu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

        <span class="c1"># Initialization from the original implementation</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.414</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.414</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_feats</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">,</span> <span class="n">print_attn_probs</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            node_feats: Input features of the node. Shape: [batch_size, c_in]</span>
<span class="sd">            adj_matrix: Adjacency matrix including self-connections. Shape: [batch_size, num_nodes, num_nodes]</span>
<span class="sd">            print_attn_probs: If True, the attention weights are printed during the forward pass</span>
<span class="sd">                               (for debugging purposes)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">node_feats</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">node_feats</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Apply linear layer and sort nodes by head</span>
        <span class="n">node_feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">projection</span><span class="p">(</span><span class="n">node_feats</span><span class="p">)</span>
        <span class="n">node_feats</span> <span class="o">=</span> <span class="n">node_feats</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># We need to calculate the attention logits for every edge in the adjacency matrix</span>
        <span class="c1"># Doing this on all possible combinations of nodes is very expensive</span>
        <span class="c1"># =&gt; Create a tensor of [W*h_i||W*h_j] with i and j being the indices of all edges</span>
        <span class="c1"># Returns indices where the adjacency matrix is not 0 =&gt; edges</span>
        <span class="n">edges</span> <span class="o">=</span> <span class="n">adj_matrix</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">node_feats_flat</span> <span class="o">=</span> <span class="n">node_feats</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">edge_indices_row</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_nodes</span> <span class="o">+</span> <span class="n">edges</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">edge_indices_col</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_nodes</span> <span class="o">+</span> <span class="n">edges</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span>
        <span class="n">a_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">node_feats_flat</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">edge_indices_row</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">node_feats_flat</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">edge_indices_col</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="p">],</span>
            <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>  <span class="c1"># Index select returns a tensor with node_feats_flat being indexed at the desired positions</span>

        <span class="c1"># Calculate attention MLP output (independent for each head)</span>
        <span class="n">attn_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;bhc,hc-&gt;bh&quot;</span><span class="p">,</span> <span class="n">a_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="p">)</span>
        <span class="n">attn_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">leakyrelu</span><span class="p">(</span><span class="n">attn_logits</span><span class="p">)</span>

        <span class="c1"># Map list of attention values back into a matrix</span>
        <span class="n">attn_matrix</span> <span class="o">=</span> <span class="n">attn_logits</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">adj_matrix</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,))</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="o">-</span><span class="mf">9e15</span><span class="p">)</span>
        <span class="n">attn_matrix</span><span class="p">[</span><span class="n">adj_matrix</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">attn_logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Weighted average of attention</span>
        <span class="n">attn_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attn_matrix</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">print_attn_probs</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Attention probs</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">attn_probs</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">node_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;bijh,bjhc-&gt;bihc&quot;</span><span class="p">,</span> <span class="n">attn_probs</span><span class="p">,</span> <span class="n">node_feats</span><span class="p">)</span>

        <span class="c1"># If heads should be concatenated, we can do this by reshaping. Otherwise, take mean</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_heads</span><span class="p">:</span>
            <span class="n">node_feats</span> <span class="o">=</span> <span class="n">node_feats</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">node_feats</span> <span class="o">=</span> <span class="n">node_feats</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">node_feats</span>
</pre></div>
</div>
</div>
<p>Again, we can apply the graph attention layer on our example graph above to understand the dynamics better. As before, the input layer is initialized as an identity matrix, but we set <img class="math" src="../../_images/math/ee06d542263974017a04fb2dc754e9708a8f749f.png" alt="\mathbf{a}"/> to be a vector of arbitrary numbers to obtain different attention values. We use two heads to show the parallel, independent attention mechanisms working in the layer.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">layer</span> <span class="o">=</span> <span class="n">GATLayer</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">layer</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span>
<span class="n">layer</span><span class="o">.</span><span class="n">projection</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
<span class="n">layer</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">]])</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">out_feats</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">node_feats</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">,</span> <span class="n">print_attn_probs</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Adjacency matrix&quot;</span><span class="p">,</span> <span class="n">adj_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input features&quot;</span><span class="p">,</span> <span class="n">node_feats</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output features&quot;</span><span class="p">,</span> <span class="n">out_feats</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Attention probs
 tensor([[[[0.3543, 0.6457, 0.0000, 0.0000],
          [0.1096, 0.1450, 0.2642, 0.4813],
          [0.0000, 0.1858, 0.2885, 0.5257],
          [0.0000, 0.2391, 0.2696, 0.4913]],

         [[0.5100, 0.4900, 0.0000, 0.0000],
          [0.2975, 0.2436, 0.2340, 0.2249],
          [0.0000, 0.3838, 0.3142, 0.3019],
          [0.0000, 0.4018, 0.3289, 0.2693]]]])
Adjacency matrix tensor([[[1., 1., 0., 0.],
         [1., 1., 1., 1.],
         [0., 1., 1., 1.],
         [0., 1., 1., 1.]]])
Input features tensor([[[0., 1.],
         [2., 3.],
         [4., 5.],
         [6., 7.]]])
Output features tensor([[[1.2913, 1.9800],
         [4.2344, 3.7725],
         [4.6798, 4.8362],
         [4.5043, 4.7351]]])
</pre></div></div>
</div>
<p>We recommend that you try to calculate the attention matrix at least for one head and one node for yourself. The entries are 0 where there does not exist an edge between <img class="math" src="../../_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.png" alt="i"/> and <img class="math" src="../../_images/math/e3fc28292267f066fee7718c64f4bbfece521f24.png" alt="j"/>. For the others, we see a diverse set of attention probabilities. Moreover, the output features of node 3 and 4 are now different although they have the same neighbors.</p>
</section>
</section>
<section id="PyTorch-Geometric">
<h2>PyTorch Geometric<a class="headerlink" href="#PyTorch-Geometric" title="Permalink to this headline">¶</a></h2>
<p>We had mentioned before that implementing graph networks with adjacency matrix is simple and straight-forward but can be computationally expensive for large graphs. Many real-world graphs can reach over 200k nodes, for which adjacency matrix-based implementations fail. There are a lot of optimizations possible when implementing GNNs, and luckily, there exist packages that provide such layers. The most popular packages for PyTorch are <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/">PyTorch
Geometric</a> and the <a class="reference external" href="https://www.dgl.ai/">Deep Graph Library</a> (the latter being actually framework agnostic). Which one to use depends on the project you are planning to do and personal taste. In this tutorial, we will look at PyTorch Geometric as part of the PyTorch family.</p>
<p>PyTorch Geometric provides us a set of common graph layers, including the GCN and GAT layer we implemented above. Additionally, similar to PyTorch’s torchvision, it provides the common graph datasets and transformations on those to simplify training. Compared to our implementation above, PyTorch Geometric uses a list of index pairs to represent the edges. The details of this library will be explored further in our experiments.</p>
<p>In our tasks below, we want to allow us to pick from a multitude of graph layers. Thus, we define again below a dictionary to access those using a string:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">gnn_layer_by_name</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;GCN&quot;</span><span class="p">:</span> <span class="n">geom_nn</span><span class="o">.</span><span class="n">GCNConv</span><span class="p">,</span> <span class="s2">&quot;GAT&quot;</span><span class="p">:</span> <span class="n">geom_nn</span><span class="o">.</span><span class="n">GATConv</span><span class="p">,</span> <span class="s2">&quot;GraphConv&quot;</span><span class="p">:</span> <span class="n">geom_nn</span><span class="o">.</span><span class="n">GraphConv</span><span class="p">}</span>
</pre></div>
</div>
</div>
<p>Additionally to GCN and GAT, we added the layer <code class="docutils literal notranslate"><span class="pre">geom_nn.GraphConv</span></code> (<a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GraphConv">documentation</a>). GraphConv is a GCN with a separate weight matrix for the self-connections. Mathematically, this would be:</p>
<div class="math">
<p><img src="../../_images/math/f7ddf81a46711263649f843930f9cce022593af0.png" alt="\mathbf{x}_i^{(l+1)} = \mathbf{W}^{(l + 1)}_1 \mathbf{x}_i^{(l)} + \mathbf{W}^{(\ell + 1)}_2 \sum_{j \in \mathcal{N}_i} \mathbf{x}_j^{(l)}"/></p>
</div><p>In this formula, the neighbor’s messages are added instead of averaged. However, PyTorch Geometric provides the argument <code class="docutils literal notranslate"><span class="pre">aggr</span></code> to switch between summing, averaging, and max pooling.</p>
</section>
<section id="Experiments-on-graph-structures">
<h2>Experiments on graph structures<a class="headerlink" href="#Experiments-on-graph-structures" title="Permalink to this headline">¶</a></h2>
<div class="center-wrapper"><div class="video-wrapper"><iframe src="https://www.youtube.com/embed/ZCNSUWe4a_Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div></div><p>Tasks on graph-structured data can be grouped into three groups: node-level, edge-level and graph-level. The different levels describe on which level we want to perform classification/regression. We will discuss all three types in more detail below.</p>
<section id="Node-level-tasks:-Semi-supervised-node-classification">
<h3>Node-level tasks: Semi-supervised node classification<a class="headerlink" href="#Node-level-tasks:-Semi-supervised-node-classification" title="Permalink to this headline">¶</a></h3>
<p>Node-level tasks have the goal to classify nodes in a graph. Usually, we have given a single, large graph with &gt;1000 nodes of which a certain amount of nodes are labeled. We learn to classify those labeled examples during training and try to generalize to the unlabeled nodes.</p>
<p>A popular example that we will use in this tutorial is the Cora dataset, a citation network among papers. The Cora consists of 2708 scientific publications with links between each other representing the citation of one paper by another. The task is to classify each publication into one of seven classes. Each publication is represented by a bag-of-words vector. This means that we have a vector of 1433 elements for each publication, where a 1 at feature <img class="math" src="../../_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.png" alt="i"/> indicates that the <img class="math" src="../../_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.png" alt="i"/>-th
word of a pre-defined dictionary is in the article. Binary bag-of-words representations are commonly used when we need very simple encodings, and already have an intuition of what words to expect in a network. There exist much better approaches, but we will leave this to the NLP courses to discuss.</p>
<p>We will load the dataset below:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cora_dataset</span> <span class="o">=</span> <span class="n">torch_geometric</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">Planetoid</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">DATASET_PATH</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Cora&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph
Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index
Processing...
Done!
</pre></div></div>
</div>
<p>Let’s look at how PyTorch Geometric represents the graph data. Note that although we have a single graph, PyTorch Geometric returns a dataset for compatibility to other datasets.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">cora_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])
</pre></div></div>
</div>
<p>The graph is represented by a <code class="docutils literal notranslate"><span class="pre">Data</span></code> object (<a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data">documentation</a>) which we can access as a standard Python namespace. The edge index tensor is the list of edges in the graph and contains the mirrored version of each edge for undirected graphs. The <code class="docutils literal notranslate"><span class="pre">train_mask</span></code>, <code class="docutils literal notranslate"><span class="pre">val_mask</span></code>, and <code class="docutils literal notranslate"><span class="pre">test_mask</span></code> are boolean masks that indicate which nodes we should use for training, validation, and testing. The <code class="docutils literal notranslate"><span class="pre">x</span></code>
tensor is the feature tensor of our 2708 publications, and <code class="docutils literal notranslate"><span class="pre">y</span></code> the labels for all nodes.</p>
<p>After having seen the data, we can implement a simple graph neural network. The GNN applies a sequence of graph layers (GCN, GAT, or GraphConv), ReLU as activation function, and dropout for regularization. See below for the specific implementation.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">GNNModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">c_in</span><span class="p">,</span>
        <span class="n">c_hidden</span><span class="p">,</span>
        <span class="n">c_out</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">layer_name</span><span class="o">=</span><span class="s2">&quot;GCN&quot;</span><span class="p">,</span>
        <span class="n">dp_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            c_in: Dimension of input features</span>
<span class="sd">            c_hidden: Dimension of hidden features</span>
<span class="sd">            c_out: Dimension of the output features. Usually number of classes in classification</span>
<span class="sd">            num_layers: Number of &quot;hidden&quot; graph layers</span>
<span class="sd">            layer_name: String of the graph layer to use</span>
<span class="sd">            dp_rate: Dropout rate to apply throughout the network</span>
<span class="sd">            kwargs: Additional arguments for the graph layer (e.g. number of heads for GAT)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">gnn_layer</span> <span class="o">=</span> <span class="n">gnn_layer_by_name</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="n">c_in</span><span class="p">,</span> <span class="n">c_hidden</span>
        <span class="k">for</span> <span class="n">l_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="n">gnn_layer</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dp_rate</span><span class="p">),</span>
            <span class="p">]</span>
            <span class="n">in_channels</span> <span class="o">=</span> <span class="n">c_hidden</span>
        <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">gnn_layer</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">c_out</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            x: Input features per node</span>
<span class="sd">            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="c1"># For graph layers, we need to add the &quot;edge_index&quot; tensor as additional input</span>
            <span class="c1"># All PyTorch Geometric graph layer inherit the class &quot;MessagePassing&quot;, hence</span>
            <span class="c1"># we can simply check the class type.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">geom_nn</span><span class="o">.</span><span class="n">MessagePassing</span><span class="p">):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<p>Good practice in node-level tasks is to create an MLP baseline that is applied to each node independently. This way we can verify whether adding the graph information to the model indeed improves the prediction, or not. It might also be that the features per node are already expressive enough to clearly point towards a specific class. To check this, we implement a simple MLP below.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">MLPModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_in</span><span class="p">,</span> <span class="n">c_hidden</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dp_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            c_in: Dimension of input features</span>
<span class="sd">            c_hidden: Dimension of hidden features</span>
<span class="sd">            c_out: Dimension of the output features. Usually number of classes in classification</span>
<span class="sd">            num_layers: Number of hidden layers</span>
<span class="sd">            dp_rate: Dropout rate to apply throughout the network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span> <span class="o">=</span> <span class="n">c_in</span><span class="p">,</span> <span class="n">c_hidden</span>
        <span class="k">for</span> <span class="n">l_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dp_rate</span><span class="p">)]</span>
            <span class="n">in_channels</span> <span class="o">=</span> <span class="n">c_hidden</span>
        <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">c_out</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            x: Input features per node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Finally, we can merge the models into a PyTorch Lightning module which handles the training, validation, and testing for us.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">NodeLevelGNN</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Saving hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s2">&quot;MLP&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">MLPModel</span><span class="p">(</span><span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">GNNModel</span><span class="p">(</span><span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>

        <span class="c1"># Only calculate the loss on the nodes corresponding to the mask</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_mask</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;val&quot;</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">val_mask</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">test_mask</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;Unknown forward mode: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">mode</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_module</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># We use SGD here, but Adam works as well</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">2e-3</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">optimizer</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_acc&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test_acc&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Additionally to the Lightning module, we define a training function below. As we have a single graph, we use a batch size of 1 for the data loader and share the same data loader for the train, validation, and test set (the mask is picked inside the Lightning module). Besides, we set the argument <code class="docutils literal notranslate"><span class="pre">progress_bar_refresh_rate</span></code> to zero as it usually shows the progress per epoch, but an epoch only consists of a single step. If you have downloaded the pre-trained models in the beginning of the
tutorial, we load those instead of training from scratch. Finally, we test the model and return the results.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">train_node_classifier</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">):</span>
    <span class="n">pl</span><span class="o">.</span><span class="n">seed_everything</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">node_data_loader</span> <span class="o">=</span> <span class="n">geom_data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Create a PyTorch Lightning trainer</span>
    <span class="n">root_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="s2">&quot;NodeLevel&quot;</span> <span class="o">+</span> <span class="n">model_name</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
        <span class="n">default_root_dir</span><span class="o">=</span><span class="n">root_dir</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">save_weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">)],</span>
        <span class="n">gpus</span><span class="o">=</span><span class="n">AVAIL_GPUS</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="n">progress_bar_refresh_rate</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span>  <span class="c1"># 0 because epoch size is 1</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">_default_hp_metric</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Optional logging argument that we don&#39;t need</span>

    <span class="c1"># Check whether pretrained model exists. If yes, load it and skip training</span>
    <span class="n">pretrained_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="s2">&quot;NodeLevel</span><span class="si">%s</span><span class="s2">.ckpt&quot;</span> <span class="o">%</span> <span class="n">model_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">pretrained_filename</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Found pretrained model, loading...&quot;</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">NodeLevelGNN</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">pretrained_filename</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">seed_everything</span><span class="p">()</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">NodeLevelGNN</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span> <span class="n">c_in</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_node_features</span><span class="p">,</span> <span class="n">c_out</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span>
        <span class="p">)</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">node_data_loader</span><span class="p">,</span> <span class="n">node_data_loader</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">NodeLevelGNN</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">checkpoint_callback</span><span class="o">.</span><span class="n">best_model_path</span><span class="p">)</span>

    <span class="c1"># Test best model on the test set</span>
    <span class="n">test_result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_dataloaders</span><span class="o">=</span><span class="n">node_data_loader</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">node_data_loader</span><span class="p">))</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_acc</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">:</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">test_result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;test_acc&quot;</span><span class="p">]}</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">result</span>
</pre></div>
</div>
</div>
<p>Now, we can train our models. First, let’s train the simple MLP:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Small function for printing the test scores</span>
<span class="k">def</span> <span class="nf">print_results</span><span class="p">(</span><span class="n">result_dict</span><span class="p">):</span>
    <span class="k">if</span> <span class="s2">&quot;train&quot;</span> <span class="ow">in</span> <span class="n">result_dict</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train accuracy: </span><span class="si">%4.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">*</span> <span class="n">result_dict</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]))</span>
    <span class="k">if</span> <span class="s2">&quot;val&quot;</span> <span class="ow">in</span> <span class="n">result_dict</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Val accuracy:   </span><span class="si">%4.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">*</span> <span class="n">result_dict</span><span class="p">[</span><span class="s2">&quot;val&quot;</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy:  </span><span class="si">%4.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">*</span> <span class="n">result_dict</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">node_mlp_model</span><span class="p">,</span> <span class="n">node_mlp_result</span> <span class="o">=</span> <span class="n">train_node_classifier</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;MLP&quot;</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">cora_dataset</span><span class="p">,</span> <span class="n">c_hidden</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dp_rate</span><span class="o">=</span><span class="mf">0.1</span>
<span class="p">)</span>

<span class="n">print_results</span><span class="p">(</span><span class="n">node_mlp_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Global seed set to 42
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
/home/AzDevOps_azpcontainer/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:678: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Found pretrained model, loading...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Missing logger folder: saved_models/GNNs/NodeLevelMLP/lightning_logs
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train accuracy: 97.14%
Val accuracy:   54.60%
Test accuracy:  60.60%
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/AzDevOps_azpcontainer/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
</pre></div></div>
</div>
<p>Although the MLP can overfit on the training dataset because of the high-dimensional input features, it does not perform too well on the test set. Let’s see if we can beat this score with our graph networks:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">node_gnn_model</span><span class="p">,</span> <span class="n">node_gnn_result</span> <span class="o">=</span> <span class="n">train_node_classifier</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;GNN&quot;</span><span class="p">,</span> <span class="n">layer_name</span><span class="o">=</span><span class="s2">&quot;GCN&quot;</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">cora_dataset</span><span class="p">,</span> <span class="n">c_hidden</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dp_rate</span><span class="o">=</span><span class="mf">0.1</span>
<span class="p">)</span>
<span class="n">print_results</span><span class="p">(</span><span class="n">node_gnn_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Global seed set to 42
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Missing logger folder: saved_models/GNNs/NodeLevelGNN/lightning_logs
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Found pretrained model, loading...
Train accuracy: 100.00%
Val accuracy:   78.00%
Test accuracy:  82.40%
</pre></div></div>
</div>
<p>As we would have hoped for, the GNN model outperforms the MLP by quite a margin. This shows that using the graph information indeed improves our predictions and lets us generalizes better.</p>
<p>The hyperparameters in the model have been chosen to create a relatively small network. This is because the first layer with an input dimension of 1433 can be relatively expensive to perform for large graphs. In general, GNNs can become relatively expensive for very big graphs. This is why such GNNs either have a small hidden size or use a special batching strategy where we sample a connected subgraph of the big, original graph.</p>
</section>
<section id="Edge-level-tasks:-Link-prediction">
<h3>Edge-level tasks: Link prediction<a class="headerlink" href="#Edge-level-tasks:-Link-prediction" title="Permalink to this headline">¶</a></h3>
<p>In some applications, we might have to predict on an edge-level instead of node-level. The most common edge-level task in GNN is link prediction. Link prediction means that given a graph, we want to predict whether there will be/should be an edge between two nodes or not. For example, in a social network, this is used by Facebook and co to propose new friends to you. Again, graph level information can be crucial to perform this task. The output prediction is usually done by performing a
similarity metric on the pair of node features, which should be 1 if there should be a link, and otherwise close to 0. To keep the tutorial short, we will not implement this task ourselves. Nevertheless, there are many good resources out there if you are interested in looking closer at this task. Tutorials and papers for this topic include:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/rusty1s/pytorch_geometric/blob/master/examples/link_pred.py">PyTorch Geometric example</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1812.08434.pdf">Graph Neural Networks: A Review of Methods and Applications</a>, Zhou et al. 2019</p></li>
<li><p><a class="reference external" href="https://papers.nips.cc/paper/2018/file/53f0d7c537d99b3824f0f99d62ea2428-Paper.pdf">Link Prediction Based on Graph Neural Networks</a>, Zhang and Chen, 2018.</p></li>
</ul>
</section>
<section id="Graph-level-tasks:-Graph-classification">
<h3>Graph-level tasks: Graph classification<a class="headerlink" href="#Graph-level-tasks:-Graph-classification" title="Permalink to this headline">¶</a></h3>
<p>Finally, in this part of the tutorial, we will have a closer look at how to apply GNNs to the task of graph classification. The goal is to classify an entire graph instead of single nodes or edges. Therefore, we are also given a dataset of multiple graphs that we need to classify based on some structural graph properties. The most common task for graph classification is molecular property prediction, in which molecules are represented as graphs. Each atom is linked to a node, and edges in the
graph are the bonds between atoms. For example, look at the figure below.</p>
<center width="100%"><p><img alt="ba671c40557e42cbafcf4e973b91516b" class="no-scaled-link" src="https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/06-graph-neural-networks/molecule_graph.svg" width="600px" /></p>
</center><p>On the left, we have an arbitrary, small molecule with different atoms, whereas the right part of the image shows the graph representation. The atom types are abstracted as node features (e.g. a one-hot vector), and the different bond types are used as edge features. For simplicity, we will neglect the edge attributes in this tutorial, but you can include by using methods like the <a class="reference external" href="https://arxiv.org/abs/1703.06103">Relational Graph Convolution</a> that uses a different weight matrix for each
edge type.</p>
<p>The dataset we will use below is called the MUTAG dataset. It is a common small benchmark for graph classification algorithms, and contain 188 graphs with 18 nodes and 20 edges on average for each graph. The graph nodes have 7 different labels/atom types, and the binary graph labels represent “their mutagenic effect on a specific gram negative bacterium” (the specific meaning of the labels are not too important here). The dataset is part of a large collection of different graph classification
datasets, known as the <a class="reference external" href="https://chrsmrrs.github.io/datasets/">TUDatasets</a>, which is directly accessible via <code class="docutils literal notranslate"><span class="pre">torch_geometric.datasets.TUDataset</span></code> (<a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.TUDataset">documentation</a>) in PyTorch Geometric. We can load the dataset below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">tu_dataset</span> <span class="o">=</span> <span class="n">torch_geometric</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">TUDataset</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">DATASET_PATH</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;MUTAG&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip
Extracting /__w/2/s/.datasets/MUTAG/MUTAG.zip
Processing...
Done!
</pre></div></div>
</div>
<p>Let’s look at some statistics for the dataset:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data object:&quot;</span><span class="p">,</span> <span class="n">tu_dataset</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Length:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tu_dataset</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average label: </span><span class="si">%4.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tu_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Data object: Data(edge_attr=[7442, 4], edge_index=[2, 7442], x=[3371, 7], y=[188])
Length: 188
Average label: 0.66
</pre></div></div>
</div>
<p>The first line shows how the dataset stores different graphs. The nodes, edges, and labels of each graph are concatenated to one tensor, and the dataset stores the indices where to split the tensors correspondingly. The length of the dataset is the number of graphs we have, and the “average label” denotes the percentage of the graph with label 1. As long as the percentage is in the range of 0.5, we have a relatively balanced dataset. It happens quite often that graph datasets are very
imbalanced, hence checking the class balance is always a good thing to do.</p>
<p>Next, we will split our dataset into a training and test part. Note that we do not use a validation set this time because of the small size of the dataset. Therefore, our model might overfit slightly on the validation set due to the noise of the evaluation, but we still get an estimate of the performance on untrained data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tu_dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">()</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tu_dataset</span><span class="p">[:</span><span class="mi">150</span><span class="p">]</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tu_dataset</span><span class="p">[</span><span class="mi">150</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<p>When using a data loader, we encounter a problem with batching <img class="math" src="../../_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.png" alt="N"/> graphs. Each graph in the batch can have a different number of nodes and edges, and hence we would require a lot of padding to obtain a single tensor. Torch geometric uses a different, more efficient approach: we can view the <img class="math" src="../../_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.png" alt="N"/> graphs in a batch as a single large graph with concatenated node and edge list. As there is no edge between the <img class="math" src="../../_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.png" alt="N"/> graphs, running GNN layers on the large graph gives us the same
output as running the GNN on each graph separately. Visually, this batching strategy is visualized below (figure credit - PyTorch Geometric team, <a class="reference external" href="https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=2owRWKcuoALo">tutorial here</a>).</p>
<center width="100%"><p><img alt="400ad8356fca42ca892caf44df66907a" class="no-scaled-link" src="https://github.com/PyTorchLightning/lightning-tutorials/raw/main/course_UvA-DL/06-graph-neural-networks/torch_geometric_stacking_graphs.png" style="width: 600px;" /></p>
</center><p>The adjacency matrix is zero for any nodes that come from two different graphs, and otherwise according to the adjacency matrix of the individual graph. Luckily, this strategy is already implemented in torch geometric, and hence we can use the corresponding data loader:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">graph_train_loader</span> <span class="o">=</span> <span class="n">geom_data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">graph_val_loader</span> <span class="o">=</span> <span class="n">geom_data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>  <span class="c1"># Additional loader for a larger datasets</span>
<span class="n">graph_test_loader</span> <span class="o">=</span> <span class="n">geom_data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s load a batch below to see the batching in action:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">graph_test_loader</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Batch:&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Labels:&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">y</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Batch indices:&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">[:</span><span class="mi">40</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Batch: Batch(batch=[687], edge_attr=[1512, 4], edge_index=[2, 1512], ptr=[39], x=[687, 7], y=[38])
Labels: tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0])
Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])
</pre></div></div>
</div>
<p>We have 38 graphs stacked together for the test dataset. The batch indices, stored in <code class="docutils literal notranslate"><span class="pre">batch</span></code>, show that the first 12 nodes belong to the first graph, the next 22 to the second graph, and so on. These indices are important for performing the final prediction. To perform a prediction over a whole graph, we usually perform a pooling operation over all nodes after running the GNN model. In this case, we will use the average pooling. Hence, we need to know which nodes should be included in which
average pool. Using this pooling, we can already create our graph network below. Specifically, we re-use our class <code class="docutils literal notranslate"><span class="pre">GNNModel</span></code> from before, and simply add an average pool and single linear layer for the graph prediction task.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">GraphGNNModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_in</span><span class="p">,</span> <span class="n">c_hidden</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">dp_rate_linear</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            c_in: Dimension of input features</span>
<span class="sd">            c_hidden: Dimension of hidden features</span>
<span class="sd">            c_out: Dimension of output features (usually number of classes)</span>
<span class="sd">            dp_rate_linear: Dropout rate before the linear layer (usually much higher than inside the GNN)</span>
<span class="sd">            kwargs: Additional arguments for the GNNModel object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">GNN</span> <span class="o">=</span> <span class="n">GNNModel</span><span class="p">(</span><span class="n">c_in</span><span class="o">=</span><span class="n">c_in</span><span class="p">,</span> <span class="n">c_hidden</span><span class="o">=</span><span class="n">c_hidden</span><span class="p">,</span> <span class="n">c_out</span><span class="o">=</span><span class="n">c_hidden</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># Not our prediction output yet!</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dp_rate_linear</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">c_hidden</span><span class="p">,</span> <span class="n">c_out</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            x: Input features per node</span>
<span class="sd">            edge_index: List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)</span>
<span class="sd">            batch_idx: Index of batch element for each node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GNN</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">geom_nn</span><span class="o">.</span><span class="n">global_mean_pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span>  <span class="c1"># Average pooling</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<p>Finally, we can create a PyTorch Lightning module to handle the training. It is similar to the modules we have seen before and does nothing surprising in terms of training. As we have a binary classification task, we use the Binary Cross Entropy loss.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">GraphLevelGNN</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Saving hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">GraphGNNModel</span><span class="p">(</span><span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">c_out</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch_idx</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">batch</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">c_out</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">data</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_module</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">preds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span>

    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># High lr because of small dataset and small model</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">optimizer</span>

    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;train_acc&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test_acc&quot;</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Below we train the model on our dataset. It resembles the typical training functions we have seen so far.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">train_graph_classifier</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">):</span>
    <span class="n">pl</span><span class="o">.</span><span class="n">seed_everything</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># Create a PyTorch Lightning trainer with the generation callback</span>
    <span class="n">root_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="s2">&quot;GraphLevel&quot;</span> <span class="o">+</span> <span class="n">model_name</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
        <span class="n">default_root_dir</span><span class="o">=</span><span class="n">root_dir</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">save_weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">)],</span>
        <span class="n">gpus</span><span class="o">=</span><span class="n">AVAIL_GPUS</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">progress_bar_refresh_rate</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">_default_hp_metric</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Check whether pretrained model exists. If yes, load it and skip training</span>
    <span class="n">pretrained_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">CHECKPOINT_PATH</span><span class="p">,</span> <span class="s2">&quot;GraphLevel</span><span class="si">%s</span><span class="s2">.ckpt&quot;</span> <span class="o">%</span> <span class="n">model_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">pretrained_filename</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Found pretrained model, loading...&quot;</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">GraphLevelGNN</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">pretrained_filename</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">seed_everything</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">GraphLevelGNN</span><span class="p">(</span>
            <span class="n">c_in</span><span class="o">=</span><span class="n">tu_dataset</span><span class="o">.</span><span class="n">num_node_features</span><span class="p">,</span>
            <span class="n">c_out</span><span class="o">=</span><span class="mi">1</span> <span class="k">if</span> <span class="n">tu_dataset</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">==</span> <span class="mi">2</span> <span class="k">else</span> <span class="n">tu_dataset</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="o">**</span><span class="n">model_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">graph_train_loader</span><span class="p">,</span> <span class="n">graph_val_loader</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">GraphLevelGNN</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">checkpoint_callback</span><span class="o">.</span><span class="n">best_model_path</span><span class="p">)</span>

    <span class="c1"># Test best model on validation and test set</span>
    <span class="n">train_result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_dataloaders</span><span class="o">=</span><span class="n">graph_train_loader</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">test_result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_dataloaders</span><span class="o">=</span><span class="n">graph_test_loader</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">test_result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;test_acc&quot;</span><span class="p">],</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;test_acc&quot;</span><span class="p">]}</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">result</span>
</pre></div>
</div>
</div>
<p>Finally, let’s perform the training and testing. Feel free to experiment with different GNN layers, hyperparameters, etc.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">model</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="n">train_graph_classifier</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;GraphConv&quot;</span><span class="p">,</span> <span class="n">c_hidden</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">layer_name</span><span class="o">=</span><span class="s2">&quot;GraphConv&quot;</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dp_rate_linear</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dp_rate</span><span class="o">=</span><span class="mf">0.0</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Global seed set to 42
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Missing logger folder: saved_models/GNNs/GraphLevelGraphConv/lightning_logs
/home/AzDevOps_azpcontainer/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:376: UserWarning: Your test_dataloader has `shuffle=True`, it is best practice to turn this off for val/test/predict dataloaders.
  rank_zero_warn(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Found pretrained model, loading...
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train performance: </span><span class="si">%4.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">*</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test performance:  </span><span class="si">%4.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">*</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Train performance: 92.67%
Test performance:  92.11%
</pre></div></div>
</div>
<p>The test performance shows that we obtain quite good scores on an unseen part of the dataset. It should be noted that as we have been using the test set for validation as well, we might have overfitted slightly to this set. Nevertheless, the experiment shows us that GNNs can be indeed powerful to predict the properties of graphs and/or molecules.</p>
</section>
</section>
<section id="Conclusion">
<h2>Conclusion<a class="headerlink" href="#Conclusion" title="Permalink to this headline">¶</a></h2>
<p>In this tutorial, we have seen the application of neural networks to graph structures. We looked at how a graph can be represented (adjacency matrix or edge list), and discussed the implementation of common graph layers: GCN and GAT. The implementations showed the practical side of the layers, which is often easier than the theory. Finally, we experimented with different tasks, on node-, edge- and graph-level. Overall, we have seen that including graph information in the predictions can be
crucial for achieving high performance. There are a lot of applications that benefit from GNNs, and the importance of these networks will likely increase over the next years.</p>
</section>
<section id="Congratulations---Time-to-Join-the-Community!">
<h2>Congratulations - Time to Join the Community!<a class="headerlink" href="#Congratulations---Time-to-Join-the-Community!" title="Permalink to this headline">¶</a></h2>
<p>Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the Lightning movement, you can do so in the following ways!</p>
<section id="Star-Lightning-on-GitHub">
<h3>Star <a class="reference external" href="https://github.com/PyTorchLightning/pytorch-lightning">Lightning</a> on GitHub<a class="headerlink" href="#Star-Lightning-on-GitHub" title="Permalink to this headline">¶</a></h3>
<p>The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we’re building.</p>
</section>
<section id="Join-our-Slack!">
<h3>Join our <a class="reference external" href="https://join.slack.com/t/pytorch-lightning/shared_invite/zt-pw5v393p-qRaDgEk24~EjiZNBpSQFgQ">Slack</a>!<a class="headerlink" href="#Join-our-Slack!" title="Permalink to this headline">¶</a></h3>
<p>The best way to keep up to date on the latest advancements is to join our community! Make sure to introduce yourself and share your interests in <code class="docutils literal notranslate"><span class="pre">#general</span></code> channel</p>
</section>
<section id="Contributions-!">
<h3>Contributions !<a class="headerlink" href="#Contributions-!" title="Permalink to this headline">¶</a></h3>
<p>The best way to contribute to our community is to become a code contributor! At any time you can go to <a class="reference external" href="https://github.com/PyTorchLightning/pytorch-lightning">Lightning</a> or <a class="reference external" href="https://github.com/PyTorchLightning/lightning-bolts">Bolt</a> GitHub Issues page and filter for “good first issue”.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/PyTorchLightning/pytorch-lightning/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22">Lightning good first issue</a></p></li>
<li><p><a class="reference external" href="https://github.com/PyTorchLightning/lightning-bolts/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22">Bolt good first issue</a></p></li>
<li><p>You can also contribute your own notebooks with useful examples !</p></li>
</ul>
</section>
<section id="Great-thanks-from-the-entire-Pytorch-Lightning-Team-for-your-interest-!">
<h3>Great thanks from the entire Pytorch Lightning Team for your interest !<a class="headerlink" href="#Great-thanks-from-the-entire-Pytorch-Lightning-Team-for-your-interest-!" title="Permalink to this headline">¶</a></h3>
<p><a class="reference internal" href="data:image/png;base64,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"><img alt="Pytorch Lightning" src="data:image/png;base64,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" style="width: 240px; height: 60px;" /></a></p>
</section>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="07-deep-energy-based-generative-models.html" class="btn btn-neutral float-right" title="Tutorial 7: Deep Energy-Based Generative Models" accesskey="n" rel="next">Next <img src="../../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="05-transformers-and-MH-attention.html" class="btn btn-neutral" title="Tutorial 5: Transformers and Multi-Head Attention" accesskey="p" rel="prev"><img src="../../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright Copyright (c) 2020-2021, PytorchLightning team..

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Tutorial 6: Basics of Graph Neural Networks</a><ul>
<li><a class="reference internal" href="#Setup">Setup</a></li>
<li><a class="reference internal" href="#Graph-Neural-Networks">Graph Neural Networks</a><ul>
<li><a class="reference internal" href="#Graph-representation">Graph representation</a></li>
<li><a class="reference internal" href="#Graph-Convolutions">Graph Convolutions</a></li>
<li><a class="reference internal" href="#Graph-Attention">Graph Attention</a></li>
</ul>
</li>
<li><a class="reference internal" href="#PyTorch-Geometric">PyTorch Geometric</a></li>
<li><a class="reference internal" href="#Experiments-on-graph-structures">Experiments on graph structures</a><ul>
<li><a class="reference internal" href="#Node-level-tasks:-Semi-supervised-node-classification">Node-level tasks: Semi-supervised node classification</a></li>
<li><a class="reference internal" href="#Edge-level-tasks:-Link-prediction">Edge-level tasks: Link prediction</a></li>
<li><a class="reference internal" href="#Graph-level-tasks:-Graph-classification">Graph-level tasks: Graph classification</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Conclusion">Conclusion</a></li>
<li><a class="reference internal" href="#Congratulations---Time-to-Join-the-Community!">Congratulations - Time to Join the Community!</a><ul>
<li><a class="reference internal" href="#Star-Lightning-on-GitHub">Star Lightning on GitHub</a></li>
<li><a class="reference internal" href="#Join-our-Slack!">Join our Slack!</a></li>
<li><a class="reference internal" href="#Contributions-!">Contributions !</a></li>
<li><a class="reference internal" href="#Great-thanks-from-the-entire-Pytorch-Lightning-Team-for-your-interest-!">Great thanks from the entire Pytorch Lightning Team for your interest !</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <!--
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://lightning-sandbox.rtfd.io/en/latest">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pt-lightning-sandbox.readthedocs.io/en/latest/#tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pt-lightning-sandbox.readthedocs.io/en/latest/#community-examples">View Resources</a>
        </div>
        -->
      </div>
    </div>
  </div>

  <!--
  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pt-lightning-sandbox.rtfd.io/en/latest/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pt-lightning-sandbox.rtfd.io/en/latest/">PyTorch</a></li>
            <li><a href="https://pt-lightning-sandbox.readthedocs.io/en/latest/introduction_guide.html">Get Started</a></li>
            <li><a href="https://pt-lightning-sandbox.rtfd.io/en/latest/">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="https://www.pytorchlightning.ai/blog">Blog</a></li>
            <li><a href="https://github.com/PytorchLightning/pytorch-lightning/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pt-lightning-sandbox.readthedocs.io/en/latest/#community-examples">Resources</a></li>
            <li><a href="https://pt-lightning-sandbox.readthedocs.io/en/latest/#tutorials">Tutorials</a></li>
            <li><a href="https://lightning-sandbox.rtfd.io/en/latest">Docs</a></li>
            <li><a href="https://pytorch-lightning.slack.com" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/PytorchLightning/lightning-sandbox/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/PyTorchLightnin" target="_blank" class="twitter"></a>
            <a href="" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>
  -->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. Read PyTorch Lightning's <a href="https://pytorchlightning.ai/privacy-policy">Privacy Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pt-lightning-sandbox.rtfd.io/en/latest/" aria-label="PyTorch Lightning"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pt-lightning-sandbox.readthedocs.io/en/latest/introduction_guide.html">Get Started</a>
          </li>

          <li>
            <a href="https://www.pytorchlightning.ai/blog">Blog</a>
          </li>

          <li class="resources-mobile-menu-title">
            Ecosystem
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch-lightning.readthedocs.io/en/stable/">PyTorch Lightning</a>
            </li>

            <li>
              <a href="https://torchmetrics.readthedocs.io/en/stable/">TorchMetrics</a>
            </li>

            <li>
              <a href="https://lightning-flash.readthedocs.io/en/stable/">Lightning Flash</a>
            </li>

            <li>
              <a href="https://lightning-transformers.readthedocs.io/en/stable/">Lightning Transformers</a>
            </li>

            <li>
              <a href="https://lightning-bolts.readthedocs.io/en/stable/">Lightning Bolts</a>
            </li>
          </ul>

          <!--<li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pt-lightning-sandbox.readthedocs.io/en/latest/#community-examples">Developer Resources</a>
            </li>

            <li>
              <a href="https://pt-lightning-sandbox.rtfd.io/en/latest/">About</a>
            </li>

            <li>
              <a href="">Models (Beta)</a>
            </li>

            <li>
              <a href="">Community</a>
            </li>

            <li>
              <a href="">Forums</a>
            </li>
          </ul>-->

          <li>
            <a href="https://github.com/PytorchLightning/lightning-sandbox">Github</a>
          </li>

          <li>
            <a href="https://www.grid.ai/">Grid.ai</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })                                                                                         
  </script>

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PQBQ3CV"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
 </body>
</html>